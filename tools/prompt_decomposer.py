import json
import re
from typing import Dict, Any, List, Optional
from llm.llm_router import LLMRouter

# Promethyn elite standards context for tool/code generation
STANDARD_CONTEXT = (
    "You are Promethyn's code generator. Enforce these elite standards at all times:\n"
    "- All tools must follow the BaseTool interface and Promethyn modular architecture.\n"
    "- Every tool must include production-grade docstrings, robust and safe fallback logic, and corresponding tests.\n"
    "- Never overwrite existing files unless explicitly allowed by the user.\n"
    "- After generation, validate tools using tool.run('test').\n"
    "- Log any validation failures to AddOnNotebook if available.\n"
    "- Always implement overwrite protection using os.path.exists().\n"
    "- Write clean, modular, future-proof Python 3.11+ code.\n"
    "- Never remove or break existing logicâ€”only enhance and extend safely.\n"
    "- The goal is to make Promethyn code better than any human or team. Do not settle.\n"
)

class PromptDecomposer:
    """
    Decomposes natural language prompts into actionable coding plans using a local or placeholder LLM.
    The LLM call is modular and can be swapped for a production LLM later.
    """

    # --- ADDITIONS BEGIN ---

    NON_TOOL_MODULE_TYPES = [
        ("memory", ["memory", "recall", "memor", "knowledge graph", "store"]),
        ("agent", ["agent", "autonomous", "reason", "act", "goal", "task agent"]),
        ("planner", ["plan", "planner", "roadmap", "strategy", "workflow"]),
        ("analyzer", ["analyz", "analysis", "inspect", "summariz", "report"]),
        ("router", ["route", "router", "dispatch", "delegate"]),
    ]

    def detect_module_type(self, prompt: str) -> str:
        """
        Detects the module type (e.g., tool, agent, memory, planner) from the prompt.
        Returns the module type as a lowercase string (defaults to 'tool' if not detected).
        """
        prompt_lower = prompt.lower()
        for module_type, keywords in self.NON_TOOL_MODULE_TYPES:
            for kw in keywords:
                if kw in prompt_lower:
                    return module_type
        return "tool"

    def create_multifile_plan(
        self,
        module_type: str,
        prompt: str,
        base_dir: str = "modules"
    ) -> Dict[str, Any]:
        """
        Generate a multi-file build plan for non-tool modules.
        Each entry in plan["files"] contains path, class, code, and test stub.
        Ensures STANDARD_CONTEXT is injected into all prompts.
        """
        # Example: for a memory module, generate a core class, interface, and test file
        safe_name = re.sub(r"[^a-zA-Z0-9]+", "_", prompt).strip("_").lower()[:40]
        module_basename = f"{module_type}_{safe_name or 'mod'}"
        files = []

        # Main module
        class_name = "".join([word.capitalize() for word in module_basename.split("_")])
        main_path = f"{base_dir}/{module_type}/{module_basename}.py"
        files.append({
            "path": main_path,
            "class": class_name,
            "code": (
                f'"""\n{module_type.capitalize()} module auto-generated by Promethyn.\n"""\n'
                f"class {class_name}:\n"
                f"    \"\"\"{module_type.capitalize()} logic.\"\"\"\n"
                f"    def run(self, *args, **kwargs):\n"
                f"        '''Implement {module_type} logic here.'''\n"
                f"        pass\n"
            ),
            "test": (
                f"from {base_dir}.{module_type}.{module_basename} import {class_name}\n"
                f"def test_{module_basename}():\n"
                f"    mod = {class_name}()\n"
                f"    assert hasattr(mod, 'run')\n"
            )
        })

        # Interface (if applicable)
        if module_type in ("memory", "agent", "planner"):
            interface_name = f"I{class_name}"
            interface_path = f"{base_dir}/{module_type}/interfaces/{interface_name}.py"
            files.append({
                "path": interface_path,
                "class": interface_name,
                "code": (
                    f"class {interface_name}:\n"
                    f"    \"\"\"Interface for {class_name}.\"\"\"\n"
                    f"    def run(self, *args, **kwargs):\n"
                    f"        raise NotImplementedError\n"
                ),
                "test": (
                    f"from {base_dir}.{module_type}.interfaces.{interface_name} import {interface_name}\n"
                    f"def test_interface_{module_basename}():\n"
                    f"    try:\n"
                    f"        {interface_name}().run()\n"
                    f"    except NotImplementedError:\n"
                    f"        pass\n"
                )
            })

        return {
            "files": files,
            "module_type": module_type,
            "plan_generated": True,
            "original_prompt": prompt
        }

    # --- ADDITIONS END ---

    def __init__(self, config: Optional[dict] = None):
        """
        Initialize the LLMRouter for structured code generation.
        Accepts an optional config dictionary for LLMRouter. If not provided, uses a safe default config.
        """
        if config is None:
            config = { "models": ["simulated"], "use_simulation": True }
        self.llm = LLMRouter(config)

        # --- ENHANCEMENT: Modular Validator Registration ---
        self.validators = []
        self._register_default_validators()

    def _register_default_validators(self):
        """
        Registers the default validators, preserving chain order and allowing modular extension.
        Existing validators must remain registered in their canonical order.
        New validators are appended at the end of the pipeline, per elite extension requirements.
        """
        try:
            # Import existing and new validators defensively.
            # Existing validator registrations MUST NOT be altered or removed.
            # New validators are added at the end.
            from validators.math_evaluator import MathEvaluator
            from validators.test_tool_runner import TestToolRunner
        except ImportError:
            MathEvaluator = None
            TestToolRunner = None

        # Register canonical validators, if present.
        if MathEvaluator is not None:
            self.validators.append(MathEvaluator())
        if TestToolRunner is not None:
            self.validators.append(TestToolRunner())

        # --- BEGIN: ELITE EXTENSIONS (Safe/Modular) ---
        try:
            from validators.code_quality_assessor import CodeQualityAssessor
        except ImportError:
            CodeQualityAssessor = None
        try:
            from validators.security_scanner import SecurityScanner
        except ImportError:
            SecurityScanner = None
        try:
            from validators.behavioral_simulator import BehavioralSimulator
        except ImportError:
            BehavioralSimulator = None

        # Register new validators only if their classes are available.
        if CodeQualityAssessor is not None:
            self.validators.append(CodeQualityAssessor())
        if SecurityScanner is not None:
            self.validators.append(SecurityScanner())
        if BehavioralSimulator is not None:
            self.validators.append(BehavioralSimulator())
        # --- END: ELITE EXTENSIONS ---

    def decompose(self, prompt: str) -> Dict[str, Any]:
        """
        Given a prompt, returns a structured plan dictionary.
        Validates LLM output and falls back to a safe default plan as needed.
        """
        # --- ADDITION: Detect module type and use multi-file plan logic for non-tool modules ---
        module_type = self.detect_module_type(prompt)
        if module_type != "tool":
            plan = self.create_multifile_plan(module_type, prompt)
        else:
            plan = self._call_llm(prompt)
        validated_plan = self._validate_and_fallback(plan, prompt)
        return validated_plan

    def _call_llm(self, prompt: str) -> Dict[str, Any]:
        """
        Call to LLMRouter to generate a structured build plan.
        Returns a dict with keys: file, class, code, test.
        Prepends STANDARD_CONTEXT to every prompt to enforce elite standards.
        """
        try:
            full_prompt = f"{STANDARD_CONTEXT}\n{prompt}"
            response = self.llm.generate(full_prompt, task_type="code")
            plan = json.loads(response)
            if not isinstance(plan, dict):
                print("[PromptDecomposer] LLMRouter returned non-dict JSON. Falling back.")
                return {}
            return plan
        except Exception as e:
            print(f"[PromptDecomposer] LLMRouter or JSON parsing failed: {e}")
            return {}

    def _validate_and_fallback(self, plan: Dict[str, Any], prompt: str) -> Dict[str, Any]:
        """
        Ensures the plan contains required keys and valid values.
        Falls back to a simple safe plan if LLM output is missing or invalid.
        Extended: supports both legacy (file/class/code/test) and new ("files") plan formats.
        """
        # --- EXTENDED: Accept new multifile format ---
        if isinstance(plan, dict) and "files" in plan and isinstance(plan["files"], list):
            for file_entry in plan["files"]:
                if not all(k in file_entry for k in ("path", "class", "code", "test")):
                    return self._legacy_fallback(prompt)
            return plan

        # Legacy plan validation
        required_keys = {"file", "class", "code", "test"}
        if not (isinstance(plan, dict) and required_keys.issubset(plan) and all(plan.get(k) for k in required_keys)):
            return self._legacy_fallback(prompt)
        return plan

    def _legacy_fallback(self, prompt: str) -> Dict[str, Any]:
        """Fallback: very basic plan for legacy single-file case."""
        return {
            "file": "tools/undefined_module.py",
            "class": "UndefinedModule",
            "code": (
                "# Auto-generated placeholder due to LLM error or incomplete output.\n"
                "class UndefinedModule:\n"
                "    def run(self, query: str) -> str:\n"
                f"        return 'No implementation. Prompt was: {prompt}'\n"
            ),
            "test": (
                "from tools.undefined_module import UndefinedModule\n"
                "mod = UndefinedModule()\n"
                "print(mod.run('test'))\n"
            )
        }

# --- EXTENSION FOR SelfCodingEngine ---

class SelfCodingEngine:
    """
    Extends the engine to support multi-file and non-tool module build plans.
    This stub assumes the existence of an existing SelfCodingEngine with a compatible interface.
    """

    # ... [existing logic remains unchanged] ...

    def build_from_plan(self, plan: Dict[str, Any], overwrite: bool = False) -> List[str]:
        """
        Build module(s) from a structured plan.
        Supports both legacy (single-file) and new (multi-file) formats.
        Implements overwrite protection and stub tests.
        Returns a list of generated file paths.
        """
        import os

        generated = []

        # Multi-file plan support
        if "files" in plan and isinstance(plan["files"], list):
            for file_spec in plan["files"]:
                path = file_spec["path"]
                code = file_spec["code"]
                # Overwrite protection
                if os.path.exists(path) and not overwrite:
                    print(f"[SelfCodingEngine] File exists and overwrite is False: {path}")
                    continue
                os.makedirs(os.path.dirname(path), exist_ok=True)
                with open(path, "w", encoding="utf-8") as f:
                    f.write(code)
                generated.append(path)
                # Optional: generate stub test files as needed

        # Legacy single-file plan
        elif all(k in plan for k in ("file", "code")):
            path = plan["file"]
            code = plan["code"]
            if os.path.exists(path) and not overwrite:
                print(f"[SelfCodingEngine] File exists and overwrite is False: {path}")
            else:
                os.makedirs(os.path.dirname(path), exist_ok=True)
                with open(path, "w", encoding="utf-8") as f:
                    f.write(code)
                generated.append(path)

        else:
            print("[SelfCodingEngine] Invalid plan structure.")

        return generated

    # All other existing logic must remain unchanged.
